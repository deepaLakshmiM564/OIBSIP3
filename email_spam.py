# -*- coding: utf-8 -*-
"""email spam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sECRZ0j9ZyGS_oh8zmpq8u7cJGxrxsoO
"""

import pandas as pd
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from imblearn.over_sampling import SMOTE

# Load the dataset
data_path = '/content/archive (16).zip'  # Update with the correct path
data = pd.read_csv(data_path, encoding='latin-1')

# Preprocess the data
data = data.rename(columns={'v1': 'label', 'v2': 'message'})
data = data[['label', 'message']]

# Map labels and preprocess messages
data['label'] = data['label'].map({'ham': 0, 'spam': 1})
data['message'] = data['message'].apply(lambda x: re.sub(r'\W', ' ', x.lower().strip()))

# Analyze class distribution
print("Class Distribution Before Balancing:")
print(data['label'].value_counts())

# Stratified split
X_train, X_test, y_train, y_test = train_test_split(data['message'], data['label'],
                                                    test_size=0.2, random_state=42, stratify=data['label'])

# Feature extraction
vectorizer = TfidfVectorizer(stop_words=None, max_features=5000, ngram_range=(1, 2))
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Balance the training data using SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)

# Check class distribution after balancing
print("Class Distribution After Balancing:")
print(pd.Series(y_train_balanced).value_counts())

# Train the model
model = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)
model.fit(X_train_balanced, y_train_balanced)

# Evaluate the model
y_pred = model.predict(X_test_tfidf)
print("\nModel Evaluation:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Predict on new input
new_email = input("\nEnter an email message: ")
new_email_cleaned = re.sub(r'\W', ' ', new_email.lower().strip())
new_email_tfidf = vectorizer.transform([new_email_cleaned])
prediction = model.predict(new_email_tfidf)[0]
print("Prediction:", "Spam" if prediction == 1 else "Not Spam")

import matplotlib.pyplot as plt

data['label'].value_counts().plot(kind='bar', color=['blue', 'orange'])
plt.title("Spam vs Non-Spam Email Count")
plt.xlabel("Class (0 = Not Spam, 1 = Spam)")
plt.ylabel("Number of Emails")
plt.xticks(rotation=0)
plt.show()

from wordcloud import WordCloud

spam_words = ' '.join(data[data['label'] == 1]['message'])
non_spam_words = ' '.join(data[data['label'] == 0]['message'])

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.title("Spam Emails")
spam_wordcloud = WordCloud(width=400, height=300, background_color='black').generate(spam_words)
plt.imshow(spam_wordcloud, interpolation='bilinear')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title("Non-Spam Emails")
non_spam_wordcloud = WordCloud(width=400, height=300, background_color='black').generate(non_spam_words)
plt.imshow(non_spam_wordcloud, interpolation='bilinear')
plt.axis('off')

plt.tight_layout()
plt.show()

import numpy as np

feature_names = vectorizer.get_feature_names_out()
feature_scores = np.asarray(X_train_tfidf.mean(axis=0)).flatten()
top_indices = feature_scores.argsort()[-20:][::-1]

plt.barh(range(len(top_indices)), feature_scores[top_indices], align='center', color='skyblue')
plt.yticks(range(len(top_indices)), [feature_names[i] for i in top_indices])
plt.gca().invert_yaxis()
plt.title("Top 20 TF-IDF Features")
plt.xlabel("Average TF-IDF Score")
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Spam', 'Spam'])
disp.plot(cmap='Blues')
plt.title("Confusion Matrix")
plt.show()